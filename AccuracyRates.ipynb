{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 3s 66us/step - loss: 1.4214 - accuracy: 0.6623 - val_loss: 0.7142 - val_accuracy: 0.8489\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 3s 61us/step - loss: 0.5760 - accuracy: 0.8573 - val_loss: 0.4416 - val_accuracy: 0.8837\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.4325 - accuracy: 0.8821 - val_loss: 0.3700 - val_accuracy: 0.8978\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 3s 70us/step - loss: 0.3779 - accuracy: 0.8950 - val_loss: 0.3350 - val_accuracy: 0.9038\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.3462 - accuracy: 0.9025 - val_loss: 0.3116 - val_accuracy: 0.9101\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 3s 61us/step - loss: 0.3236 - accuracy: 0.9083 - val_loss: 0.2944 - val_accuracy: 0.9151\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 3s 60us/step - loss: 0.3057 - accuracy: 0.9134 - val_loss: 0.2794 - val_accuracy: 0.9208\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 3s 59us/step - loss: 0.2907 - accuracy: 0.9172 - val_loss: 0.2669 - val_accuracy: 0.9229\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 3s 60us/step - loss: 0.2783 - accuracy: 0.9206 - val_loss: 0.2571 - val_accuracy: 0.9268\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.2670 - accuracy: 0.9241 - val_loss: 0.2486 - val_accuracy: 0.9282\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 3s 60us/step - loss: 0.2568 - accuracy: 0.9271 - val_loss: 0.2395 - val_accuracy: 0.9312\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.2473 - accuracy: 0.9294 - val_loss: 0.2323 - val_accuracy: 0.9346\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 3s 59us/step - loss: 0.2387 - accuracy: 0.9324 - val_loss: 0.2274 - val_accuracy: 0.9344\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 3s 61us/step - loss: 0.2310 - accuracy: 0.9342 - val_loss: 0.2196 - val_accuracy: 0.9375\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 3s 61us/step - loss: 0.2234 - accuracy: 0.9367 - val_loss: 0.2127 - val_accuracy: 0.9396\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.2166 - accuracy: 0.9389 - val_loss: 0.2069 - val_accuracy: 0.9433\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 3s 60us/step - loss: 0.2101 - accuracy: 0.9403 - val_loss: 0.2017 - val_accuracy: 0.9452\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.2040 - accuracy: 0.9418 - val_loss: 0.1971 - val_accuracy: 0.9452\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 3s 61us/step - loss: 0.1982 - accuracy: 0.9434 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 3s 70us/step - loss: 0.1929 - accuracy: 0.9452 - val_loss: 0.1882 - val_accuracy: 0.9487\n",
      "10000/10000 [==============================] - 1s 53us/step\n",
      "Test score:  0.19098283562883736\n",
      "Test accuracy:  0.9452999830245972\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(1671) # for reproducibility\n",
    "\n",
    "#network and training\n",
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "OPTIMIZER = SGD() #optimizer\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT = 0.2 # how much Train is reserved for Validation\n",
    "\n",
    "# data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#normalize\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices \n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# M_HIDDEN hidden layers \n",
    "# 10 outputs\n",
    "# final stage of softmax\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape = (RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer = OPTIMIZER,\n",
    "             metrics = ['accuracy'])\n",
    "history = model.fit(X_train, Y_train,\n",
    "                   batch_size = BATCH_SIZE, epochs = NB_EPOCH,\n",
    "                   verbose = VERBOSE, validation_split = VALIDATION_SPLIT)\n",
    "score = model.evaluate(X_test, Y_test, verbose = VERBOSE)\n",
    "print(\"Test score: \", score[0])\n",
    "print (\"Test accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/1\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 1.4881 - accuracy: 0.6275 - val_loss: 0.7539 - val_accuracy: 0.8407\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "Test score:  0.7556238098144531\n",
      "Test accuracy:  0.8395000100135803\n"
     ]
    }
   ],
   "source": [
    "#Experiement 2\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(1671) # for reproducibility\n",
    "\n",
    "#network and training\n",
    "NB_EPOCH = 1 #change number of Epoch from 20 to 1\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "OPTIMIZER = SGD() #optimizer\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT = 0.2 # how much Train is reserved for Validation\n",
    "\n",
    "# data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#normalize\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices \n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# M_HIDDEN hidden layers \n",
    "# 10 outputs\n",
    "# final stage of softmax\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape = (RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer = OPTIMIZER,\n",
    "             metrics = ['accuracy'])\n",
    "history = model.fit(X_train, Y_train,\n",
    "                   batch_size = BATCH_SIZE, epochs = NB_EPOCH,\n",
    "                   verbose = VERBOSE, validation_split = VALIDATION_SPLIT)\n",
    "score = model.evaluate(X_test, Y_test, verbose = VERBOSE)\n",
    "print(\"Test score: \", score[0])\n",
    "print (\"Test accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/40\n",
      "48000/48000 [==============================] - 4s 76us/step - loss: 1.3976 - accuracy: 0.6579 - val_loss: 0.6982 - val_accuracy: 0.8401\n",
      "Epoch 2/40\n",
      "48000/48000 [==============================] - 3s 72us/step - loss: 0.5778 - accuracy: 0.8502 - val_loss: 0.4432 - val_accuracy: 0.8837\n",
      "Epoch 3/40\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.4335 - accuracy: 0.8814 - val_loss: 0.3695 - val_accuracy: 0.8991\n",
      "Epoch 4/40\n",
      "48000/48000 [==============================] - 3s 65us/step - loss: 0.3764 - accuracy: 0.8955 - val_loss: 0.3344 - val_accuracy: 0.9059\n",
      "Epoch 5/40\n",
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.3439 - accuracy: 0.9033 - val_loss: 0.3105 - val_accuracy: 0.9117\n",
      "Epoch 6/40\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.3212 - accuracy: 0.9093 - val_loss: 0.2935 - val_accuracy: 0.9161\n",
      "Epoch 7/40\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.3031 - accuracy: 0.9137 - val_loss: 0.2791 - val_accuracy: 0.9207\n",
      "Epoch 8/40\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 0.2883 - accuracy: 0.9183 - val_loss: 0.2672 - val_accuracy: 0.9234\n",
      "Epoch 9/40\n",
      "48000/48000 [==============================] - 4s 85us/step - loss: 0.2759 - accuracy: 0.9213 - val_loss: 0.2569 - val_accuracy: 0.9268\n",
      "Epoch 10/40\n",
      "48000/48000 [==============================] - 4s 80us/step - loss: 0.2647 - accuracy: 0.9243 - val_loss: 0.2487 - val_accuracy: 0.9281\n",
      "Epoch 11/40\n",
      "48000/48000 [==============================] - 4s 79us/step - loss: 0.2546 - accuracy: 0.9276 - val_loss: 0.2397 - val_accuracy: 0.9306\n",
      "Epoch 12/40\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.2451 - accuracy: 0.9299 - val_loss: 0.2334 - val_accuracy: 0.9342\n",
      "Epoch 13/40\n",
      "48000/48000 [==============================] - 4s 78us/step - loss: 0.2367 - accuracy: 0.9327 - val_loss: 0.2276 - val_accuracy: 0.9352\n",
      "Epoch 14/40\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.2290 - accuracy: 0.9345 - val_loss: 0.2203 - val_accuracy: 0.9371\n",
      "Epoch 15/40\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.2216 - accuracy: 0.9370 - val_loss: 0.2132 - val_accuracy: 0.9398\n",
      "Epoch 16/40\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.2148 - accuracy: 0.9386 - val_loss: 0.2077 - val_accuracy: 0.9417\n",
      "Epoch 17/40\n",
      "48000/48000 [==============================] - 5s 94us/step - loss: 0.2084 - accuracy: 0.9403 - val_loss: 0.2025 - val_accuracy: 0.9434\n",
      "Epoch 18/40\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.2023 - accuracy: 0.9424 - val_loss: 0.1985 - val_accuracy: 0.9433\n",
      "Epoch 19/40\n",
      "48000/48000 [==============================] - 4s 85us/step - loss: 0.1966 - accuracy: 0.9435 - val_loss: 0.1945 - val_accuracy: 0.9458\n",
      "Epoch 20/40\n",
      "48000/48000 [==============================] - 4s 92us/step - loss: 0.1914 - accuracy: 0.9450 - val_loss: 0.1895 - val_accuracy: 0.9467\n",
      "Epoch 21/40\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.1861 - accuracy: 0.9463 - val_loss: 0.1855 - val_accuracy: 0.9487\n",
      "Epoch 22/40\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1811 - accuracy: 0.9484 - val_loss: 0.1832 - val_accuracy: 0.9481\n",
      "Epoch 23/40\n",
      "48000/48000 [==============================] - 3s 64us/step - loss: 0.1767 - accuracy: 0.9492 - val_loss: 0.1792 - val_accuracy: 0.9492\n",
      "Epoch 24/40\n",
      "48000/48000 [==============================] - 3s 71us/step - loss: 0.1724 - accuracy: 0.9505 - val_loss: 0.1756 - val_accuracy: 0.9503\n",
      "Epoch 25/40\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 0.1681 - accuracy: 0.9515 - val_loss: 0.1729 - val_accuracy: 0.9513\n",
      "Epoch 26/40\n",
      "48000/48000 [==============================] - 3s 71us/step - loss: 0.1641 - accuracy: 0.9532 - val_loss: 0.1692 - val_accuracy: 0.9521\n",
      "Epoch 27/40\n",
      "48000/48000 [==============================] - 3s 60us/step - loss: 0.1603 - accuracy: 0.9538 - val_loss: 0.1667 - val_accuracy: 0.9528\n",
      "Epoch 28/40\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.1566 - accuracy: 0.9550 - val_loss: 0.1637 - val_accuracy: 0.9532\n",
      "Epoch 29/40\n",
      "48000/48000 [==============================] - 3s 66us/step - loss: 0.1530 - accuracy: 0.9562 - val_loss: 0.1608 - val_accuracy: 0.9547\n",
      "Epoch 30/40\n",
      "48000/48000 [==============================] - 3s 64us/step - loss: 0.1497 - accuracy: 0.9575 - val_loss: 0.1588 - val_accuracy: 0.9542\n",
      "Epoch 31/40\n",
      "48000/48000 [==============================] - 3s 57us/step - loss: 0.1464 - accuracy: 0.9581 - val_loss: 0.1558 - val_accuracy: 0.9552\n",
      "Epoch 32/40\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1432 - accuracy: 0.9590 - val_loss: 0.1547 - val_accuracy: 0.9557\n",
      "Epoch 33/40\n",
      "48000/48000 [==============================] - 3s 59us/step - loss: 0.1403 - accuracy: 0.9604 - val_loss: 0.1518 - val_accuracy: 0.9570\n",
      "Epoch 34/40\n",
      "48000/48000 [==============================] - 3s 57us/step - loss: 0.1373 - accuracy: 0.9607 - val_loss: 0.1510 - val_accuracy: 0.9578\n",
      "Epoch 35/40\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.1346 - accuracy: 0.9613 - val_loss: 0.1475 - val_accuracy: 0.9582\n",
      "Epoch 36/40\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1318 - accuracy: 0.9622 - val_loss: 0.1460 - val_accuracy: 0.9587\n",
      "Epoch 37/40\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.1293 - accuracy: 0.9630 - val_loss: 0.1441 - val_accuracy: 0.9582\n",
      "Epoch 38/40\n",
      "48000/48000 [==============================] - 3s 60us/step - loss: 0.1266 - accuracy: 0.9638 - val_loss: 0.1431 - val_accuracy: 0.9591\n",
      "Epoch 39/40\n",
      "48000/48000 [==============================] - 3s 64us/step - loss: 0.1243 - accuracy: 0.9644 - val_loss: 0.1401 - val_accuracy: 0.9595\n",
      "Epoch 40/40\n",
      "48000/48000 [==============================] - 3s 57us/step - loss: 0.1218 - accuracy: 0.9649 - val_loss: 0.1387 - val_accuracy: 0.9599\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "Test score:  0.1332351804148406\n",
      "Test accuracy:  0.9607999920845032\n"
     ]
    }
   ],
   "source": [
    "# Experiement 1\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(1671) # for reproducibility\n",
    "\n",
    "#network and training\n",
    "NB_EPOCH = 40 # changes Epoch from 20 to 40\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "OPTIMIZER = SGD() #optimizer\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT = 0.2 # how much Train is reserved for Validation\n",
    "\n",
    "# data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#normalize\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices \n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# M_HIDDEN hidden layers \n",
    "# 10 outputs\n",
    "# final stage of softmax\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape = (RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer = OPTIMIZER,\n",
    "             metrics = ['accuracy'])\n",
    "history = model.fit(X_train, Y_train,\n",
    "                   batch_size = BATCH_SIZE, epochs = NB_EPOCH,\n",
    "                   verbose = VERBOSE, validation_split = VALIDATION_SPLIT)\n",
    "score = model.evaluate(X_test, Y_test, verbose = VERBOSE)\n",
    "print(\"Test score: \", score[0])\n",
    "print (\"Test accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown Cell Notes \n",
    "\n",
    "For this assignment I decided to change the parameter that dictates the number of epochs that will be ran during testing. The inital code had epochs listed as 20 and I added 2 experiments changing that number to 1 and 40.\n",
    "\n",
    "Results from all Tests.\n",
    "\n",
    "Original (20)\n",
    "    Test score:  0.19098283562883736\n",
    "    Test accuracy:  0.9452999830245972\n",
    "    \n",
    "Experiment 1 (40)\n",
    "    Test score:  0.1332351804148406\n",
    "    Test accuracy:  0.9607999920845032\n",
    "    \n",
    "Experimetnt 2 (1)\n",
    "    Test score:  0.7556238098144531\n",
    "    Test accuracy:  0.8395000100135803\n",
    "    \n",
    "Base on the results, adding more epochs increases the accuracy of the test while reducing the test score. This happens because running more test improves the statisical confidence by reducing the impact of outliers or variances allowing from a more accurate result due to the extra data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
